{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T15:08:15.854467Z",
     "start_time": "2018-09-28T15:08:15.317837Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = ('D:/Py/DataFrames/CFT_Contest(Datasouls)/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T15:08:26.273114Z",
     "start_time": "2018-09-28T15:08:15.857122Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1991104, 5)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(PATH_TO_DATA, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(PATH_TO_DATA, 'test.csv'))\n",
    "\n",
    "y_train_values = train['target'].values\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the correctness of name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA, 'train_features.pkl'), 'rb') as train_pkl:\n",
    "    train_features = pickle.load(train_pkl)\n",
    "with open(os.path.join(PATH_TO_DATA, 'test_features.pkl'), 'rb') as test_pkl:\n",
    "    test_features = pickle.load(test_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [LOAD] TEST TF-IDF pickle file\n",
    "with open(os.path.join(PATH_TO_DATA, '26_10/test_tfidf.pkl'), 'rb') as test_tfidf_pkl:\n",
    "    csr_test = pickle.load(test_tfidf_pkl)\n",
    "    \n",
    "s_test = csr_matrix(hstack([csr_test, test_features]))\n",
    "\n",
    "del csr_test, test_features, test_pkl, test_tfidf_pkl\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [LOAD] TRAIN TF-IDF pickle file\n",
    "with open(os.path.join(PATH_TO_DATA, '26_10/train_tfidf.pkl'), 'rb') as train_tfidf_pkl:\n",
    "    csr_train = pickle.load(train_tfidf_pkl)\n",
    "    \n",
    "s_train = csr_matrix(hstack([csr_train, train_features]))\n",
    "\n",
    "del csr_train, train_features, train_pkl, train_tfidf_pkl\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning (classification into 3 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_calculations(train, y, test, func_name=None):\n",
    "    if not func_name:\n",
    "        return print('The function to run is not defined')\n",
    "    else:\n",
    "        y_oof_prob = np.zeros((y.shape[0], 3))\n",
    "        test_preds_prob = []\n",
    "        avg_test_preds_prob = []\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train, y)):\n",
    "            X_train, X_val  = train[train_index], train[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "           # part to include additional functions\n",
    "            if func_name == 'logreg':\n",
    "                pred_test_prob, pred_oof_prob = run_logreg(X_train, y_train, X_val, y_val, test)\n",
    "            elif func_name == 'ridge':\n",
    "                pred_test_prob, pred_oof_prob = run_ridge(X_train, y_train, X_val, y_val, test)\n",
    "            elif func_name == 'bernoulli_nb':\n",
    "                pred_test_prob, pred_oof_prob = run_bernoulli_nb(X_train, y_train, X_val, y_val, test)\n",
    "            elif func_name == 'multinomial_nb':\n",
    "                pred_test_prob, pred_oof_prob = run_multinomial_nb(X_train, y_train, X_val, y_val, test)\n",
    "            elif func_name == 'sgd_classifier':\n",
    "                pred_test_prob, pred_oof_prob = run_sgd_classifier(X_train, y_train, X_val, y_val, test)\n",
    "            elif func_name == 'linear_svc':\n",
    "                pred_test_prob, pred_oof_prob = run_linear_svc(X_train, y_train, X_val, y_val, test)\n",
    "            else:\n",
    "                return print('The function to run is not correct')\n",
    "\n",
    "            y_oof_prob[val_index] = pred_oof_prob\n",
    "            test_preds_prob.append(list(pred_test_prob))\n",
    "\n",
    "        avg_test_preds_prob = np.mean(test_preds_prob, axis=0)\n",
    "            \n",
    "        return y_oof_prob, avg_test_preds_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_multinomial_nb(train_X, train_y, val_X, val_y, test_X):\n",
    "   \n",
    "    start_time = time.time()\n",
    "    classifier = MultinomialNB(alpha=1e-4)\n",
    "    classifier.fit(train_X, train_y)\n",
    "    print('Model training done in {} seconds.'.format(time.time() - start_time))\n",
    "    \n",
    "    pred_test_prob = classifier.predict_proba(test_X)\n",
    "    \n",
    "    pred_oof_prob = classifier.predict_proba(val_X)\n",
    "    return pred_test_prob, pred_oof_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training done in 2.1001393795013428 seconds.\n",
      "Model training done in 2.3646233081817627 seconds.\n",
      "Model training done in 6.3093931674957275 seconds.\n",
      "Model training done in 3.7238175868988037 seconds.\n",
      "Model training done in 3.964337110519409 seconds.\n",
      "Wall time: 5min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_oof_prob, test_pred_prob_list = run_calculations(s_train, y_train_values, s_test, 'multinomial_nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_oof = pd.DataFrame(train_oof_prob)\n",
    "test_pred = pd.DataFrame(test_pred_prob_list)\n",
    "\n",
    "train_oof.to_csv(os.path.join(PATH_TO_DATA, 'predictions/multinomialnb_alpha1e-4_train.csv'), index=False)\n",
    "test_pred.to_csv(os.path.join(PATH_TO_DATA, 'predictions/multinomialnb_alpha1e-4_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5329"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_oof_prob, train_oof, test_pred_prob_list, test_pred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial NB scores:**\n",
    "- F1: 0.8583698938317763\n",
    "- Precision 0.8496888639117771\n",
    "- Recall 0.871720463690965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_bernoulli_nb(train_X, train_y, val_X, val_y, test_X):\n",
    "   \n",
    "    start_time = time.time()\n",
    "    classifier = BernoulliNB(alpha=1e-5)\n",
    "    classifier.fit(train_X, train_y)\n",
    "    print('Model training done in {} seconds.'.format(time.time() - start_time))\n",
    "    \n",
    "    pred_test_prob = classifier.predict_proba(test_X)\n",
    "    \n",
    "    pred_oof_prob = classifier.predict_proba(val_X)\n",
    "    return pred_test_prob, pred_oof_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training done in 2.1167805194854736 seconds.\n",
      "Model training done in 2.6519722938537598 seconds.\n",
      "Model training done in 2.255692481994629 seconds.\n",
      "Model training done in 2.493311882019043 seconds.\n",
      "Model training done in 2.9912667274475098 seconds.\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_oof_prob, test_pred_prob_list = run_calculations(s_train, y_train_values, s_test, 'bernoulli_nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_oof = pd.DataFrame(train_oof_prob)\n",
    "test_pred = pd.DataFrame(test_pred_prob_list)\n",
    "\n",
    "train_oof.to_csv(os.path.join(PATH_TO_DATA, 'predictions/bernoullinb_alpha1e-5_train.csv'), index=False)\n",
    "test_pred.to_csv(os.path.join(PATH_TO_DATA, 'predictions/bernoullinb_alpha1e-5_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_oof_prob, train_oof, test_pred_prob_list, test_pred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bernoulli NB scores:**\n",
    "- F1: 0.8583698938317763\n",
    "- Precision 0.8496888639117771\n",
    "- Recall 0.871720463690965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_logreg(train_X, train_y, val_X, val_y, test_X):\n",
    "   \n",
    "    start_time = time.time()\n",
    "    classifier = LogisticRegression(C=50, random_state=42)\n",
    "    classifier.fit(train_X, train_y)\n",
    "    print('Model training done in {} seconds.'.format(time.time() - start_time))\n",
    "\n",
    "#    pred_test_y = classifier.predict(test_X)\n",
    "    pred_test_prob = classifier.predict_proba(test_X)\n",
    "    \n",
    "#    pred_oof = classifier.predict(val_X)\n",
    "    pred_oof_prob = classifier.predict_proba(val_X)\n",
    "    return pred_test_prob, pred_oof_prob # pred_test_y, pred_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training done in 890.8674981594086 seconds.\n",
      "Model training done in 899.4130616188049 seconds.\n",
      "Model training done in 748.1651532649994 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training done in 774.2191443443298 seconds.\n",
      "Model training done in 813.3616940975189 seconds.\n",
      "Wall time: 1h 14min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_oof_prob, test_pred_prob_list = run_calculations(s_train, y_train_values, s_test, 'logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_oof = pd.DataFrame(train_oof_prob)\n",
    "test_pred = pd.DataFrame(test_pred_prob_list)\n",
    "\n",
    "train_oof.to_csv(os.path.join(PATH_TO_DATA, 'predictions/logreg_C50_train.csv'), index=False)\n",
    "test_pred.to_csv(os.path.join(PATH_TO_DATA, 'predictions/logreg_C50_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression scores (C=50):**\n",
    "- F1: 0.922858258574291\n",
    "- Precision 0.9302636490669167\n",
    "- Recall 0.9168207153656756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training done in 720.9846198558807 seconds.\n",
      "Model training done in 669.339376449585 seconds.\n",
      "Model training done in 759.0707349777222 seconds.\n",
      "Model training done in 618.4439723491669 seconds.\n",
      "Model training done in 735.4050974845886 seconds.\n",
      "Wall time: 1h 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_oof_prob, test_pred_prob_list = run_calculations(s_train, y_train_values, s_test, 'logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_oof = pd.DataFrame(train_oof_prob)\n",
    "test_pred = pd.DataFrame(test_pred_prob_list)\n",
    "\n",
    "train_oof.to_csv(os.path.join(PATH_TO_DATA, 'predictions/logreg_C1e-1_train.csv'), index=False)\n",
    "test_pred.to_csv(os.path.join(PATH_TO_DATA, 'predictions/logreg_C1e-1_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_oof_prob, train_oof, test_pred_prob_list, test_pred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression scores (C=1e-1):**\n",
    "- F1: 0.88032509496412\n",
    "- Precision 0.9034610530262324\n",
    "- Recall 0.8621863857216052"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_linear_svc(train_X, train_y, val_X, val_y, test_X):\n",
    "   \n",
    "    start_time = time.time()\n",
    "    classifier = LinearSVC(C=1e-4, random_state=42)\n",
    "    classifier.fit(train_X, train_y)\n",
    "    print('Model training done in {} seconds.'.format(time.time() - start_time))\n",
    "\n",
    "    pred_test_prob = classifier.decision_function(test_X)\n",
    "    \n",
    "    pred_oof_prob = classifier.decision_function(val_X)\n",
    "    return pred_test_prob, pred_oof_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_ridge(train_X, train_y, val_X, val_y, test_X):\n",
    "\n",
    "    start_time = time.time()\n",
    "    classifier = RidgeClassifier(alpha=1, random_state=42)\n",
    "    classifier.fit(train_X, train_y)\n",
    "    print('Model training done in {} seconds.'.format(time.time() - start_time))\n",
    "\n",
    "    pred_test_prob = classifier.decision_function(test_X)i\n",
    "    \n",
    "    pred_oof_prob = classifier.decision_function(val_X)\n",
    "    return pred_test_prob, pred_oof_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning (binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I decided to combine target=0 and target=1 in one class to go to the task binary classification (is it Fullname or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(PATH_TO_DATA, 'train.csv'))\n",
    "train['target'] = train['target'].apply(lambda x: 1 if x == 2 else 0)\n",
    "y_train_values = train['target'].values\n",
    "\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_calculations(train, y, test, func_name=None):\n",
    "    if not func_name:\n",
    "        return print('The function to run is not defined')\n",
    "    else:\n",
    "        y_oof_prob = np.zeros((y.shape[0], 2))\n",
    "        test_preds_prob = []\n",
    "        avg_test_preds_prob = []\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        for i, (train_index, val_index) in enumerate(skf.split(train, y)):\n",
    "            X_train, X_val  = train[train_index], train[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "           # part to include additional functions\n",
    "            if func_name == 'logreg':\n",
    "                pred_test_prob, pred_oof_prob = run_logreg(X_train, y_train, X_val, y_val, test)\n",
    "            elif func_name == 'ridge':\n",
    "                pred_test_prob, pred_oof_prob = run_ridge(X_train, y_train, X_val, y_val, test)\n",
    "            elif func_name == 'bernoulli_nb':\n",
    "                pred_test_prob, pred_oof_prob = run_bernoulli_nb(X_train, y_train, X_val, y_val, test)\n",
    "            elif func_name == 'multinomial_nb':\n",
    "                pred_test_prob, pred_oof_prob = run_multinomial_nb(X_train, y_train, X_val, y_val, test)\n",
    "            elif func_name == 'sgd_classifier':\n",
    "                pred_test_prob, pred_oof_prob = run_sgd_classifier(X_train, y_train, X_val, y_val, test)\n",
    "            elif func_name == 'linear_svc':\n",
    "                pred_test_prob, pred_oof_prob = run_linear_svc(X_train, y_train, X_val, y_val, test)\n",
    "            else:\n",
    "                return print('The function to run is not correct')\n",
    "\n",
    "            y_oof_prob[val_index] = pred_oof_prob\n",
    "            test_preds_prob.append(list(pred_test_prob))\n",
    "\n",
    "        avg_test_preds_prob = np.mean(test_preds_prob, axis=0)\n",
    "            \n",
    "        return y_oof_prob, avg_test_preds_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training done in 1.2310693264007568 seconds.\n",
      "Model training done in 5.194786548614502 seconds.\n",
      "Model training done in 1.6613967418670654 seconds.\n",
      "Model training done in 1.6013519763946533 seconds.\n",
      "Model training done in 1.6900887489318848 seconds.\n",
      "Wall time: 7min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_oof_prob, test_pred_prob_list = run_calculations(s_train, y_train_values, s_test, 'multinomial_nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_oof = pd.DataFrame(train_oof_prob)\n",
    "test_pred = pd.DataFrame(test_pred_prob_list)\n",
    "\n",
    "train_oof.to_csv(os.path.join(PATH_TO_DATA, 'predictions/binary_classification/binary_multinomialnb_alpha1e-4_train.csv'), index=False)\n",
    "test_pred.to_csv(os.path.join(PATH_TO_DATA, 'predictions/binary_classification/binary_multinomialnb_alpha1e-4_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_oof_prob, train_oof, test_pred_prob_list, test_pred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial NB scores:**\n",
    "- F1: 0.9566913660488069\n",
    "- Precision 0.9788190319296961\n",
    "- Recall 0.936598856357207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training done in 2.7638161182403564 seconds.\n",
      "Model training done in 2.791532278060913 seconds.\n",
      "Model training done in 2.650484323501587 seconds.\n",
      "Model training done in 2.599717617034912 seconds.\n",
      "Model training done in 2.2613184452056885 seconds.\n",
      "Wall time: 11min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_oof_prob, test_pred_prob_list = run_calculations(s_train, y_train_values, s_test, 'bernoulli_nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_oof = pd.DataFrame(train_oof_prob)\n",
    "test_pred = pd.DataFrame(test_pred_prob_list)\n",
    "\n",
    "train_oof.to_csv(os.path.join(PATH_TO_DATA, 'predictions/binary_classification/binary_bernoullinb_alpha1e-5_train.csv'), index=False)\n",
    "test_pred.to_csv(os.path.join(PATH_TO_DATA, 'predictions/binary_classification/binary_bernoullinb_alpha1e-5_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_oof_prob, train_oof, test_pred_prob_list, test_pred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bernoulli NB scores:**\n",
    "- F1: 0.9421458133718718\n",
    "- Precision 0.9244386242294811\n",
    "- Recall 0.9614800538545566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training done in 141.974791765213 seconds.\n",
      "Model training done in 100.13427305221558 seconds.\n",
      "Model training done in 101.38522458076477 seconds.\n",
      "Model training done in 81.07326221466064 seconds.\n",
      "Model training done in 78.34653067588806 seconds.\n",
      "Wall time: 18min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_oof_prob, test_pred_prob_list = run_calculations(s_train, y_train_values, s_test, 'logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_oof = pd.DataFrame(train_oof_prob)\n",
    "test_pred = pd.DataFrame(test_pred_prob_list)\n",
    "\n",
    "train_oof.to_csv(os.path.join(PATH_TO_DATA, 'predictions/binary_classification/binary_logreg_C1e-1_train.csv'), index=False)\n",
    "test_pred.to_csv(os.path.join(PATH_TO_DATA, 'predictions/binary_classification/binary_logreg_C1e-1_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_oof_prob, train_oof, test_pred_prob_list, test_pred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression scores (C=1e-1):**\n",
    "- F1: 0.9706390851188221\n",
    "- Precision 0.9954900684218698\n",
    "- Recall 0.9482566797125438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Here I use the predicted probabilities from binary classification as additional features in Logistic Regression**\n",
    "- This trick has improved the quality of the classification into 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_multinomial = pd.read_csv(os.path.join(PATH_TO_DATA, 'predictions/binary_classification/binary_multinomialnb_alpha1e-4_train.csv'))\n",
    "test_multinomial = pd.read_csv(os.path.join(PATH_TO_DATA, 'predictions/binary_classification/binary_multinomialnb_alpha1e-4_test.csv'))\n",
    "\n",
    "train_bern = pd.read_csv(os.path.join(PATH_TO_DATA, 'predictions/binary_classification/binary_bernoullinb_alpha1e-5_train.csv'))\n",
    "test_bern = pd.read_csv(os.path.join(PATH_TO_DATA, 'predictions/binary_classification/binary_bernoullinb_alpha1e-5_test.csv'))\n",
    "\n",
    "train_logreg = pd.read_csv(os.path.join(PATH_TO_DATA, 'predictions/binary_classification/binary_logreg_C1e-1_train.csv'))\n",
    "test_logreg = pd.read_csv(os.path.join(PATH_TO_DATA, 'predictions/binary_classification/binary_logreg_C1e-1_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_biclassification_pred = []\n",
    "train_biclassification_pred.append(train_multinomial['0'].values)\n",
    "train_biclassification_pred.append(train_bern['0'].values)\n",
    "train_biclassification_pred.append(train_logreg['0'].values)\n",
    "\n",
    "test_biclassification_pred = []\n",
    "test_biclassification_pred.append(test_multinomial['0'].values)\n",
    "test_biclassification_pred.append(test_bern['0'].values)\n",
    "test_biclassification_pred.append(test_logreg['0'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1212"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_multinomial, test_multinomial, train_bern, test_bern, train_logreg, test_logreg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csr_train = csr_matrix(hstack([s_train, np.array(train_biclassification_pred).T]))\n",
    "csr_test = csr_matrix(hstack([s_test, np.array(test_biclassification_pred).T]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del s_train, train_biclassification_pred, s_test, test_biclassification_pred\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_logreg(train_X, train_y, val_X, val_y, test_X):\n",
    "   \n",
    "    start_time = time.time()\n",
    "    classifier = LogisticRegression(C=50, random_state=42)\n",
    "    classifier.fit(train_X, train_y)\n",
    "    print('Model training done in {} seconds.'.format(time.time() - start_time))\n",
    "\n",
    "    pred_test_prob = classifier.predict_proba(test_X)\n",
    "    \n",
    "    pred_oof_prob = classifier.predict_proba(val_X)\n",
    "    return pred_test_prob, pred_oof_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training done in 973.0003640651703 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training done in 942.7906486988068 seconds.\n",
      "Model training done in 1030.9394733905792 seconds.\n",
      "Model training done in 825.2373912334442 seconds.\n",
      "Model training done in 871.2575132846832 seconds.\n",
      "Wall time: 1h 21min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_oof_prob, test_pred_prob_list = run_calculations(csr_train, y_train_values, csr_test, 'logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression + вероятности 3х моделей по бинарной классификации\n",
      "F1: 0.9245931659010105\n",
      "Precision 0.9308536468556395\n",
      "Recall 0.9195525481308776\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression + вероятности 3х моделей по бинарной классификации')\n",
    "f1 = f1_score(y_train_values, np.argmax(train_oof_prob, axis=1), average='macro')\n",
    "precision = precision_score(y_train_values, np.argmax(train_oof_prob, axis=1), average='macro')\n",
    "recall = recall_score(y_train_values, np.argmax(train_oof_prob, axis=1), average='macro')\n",
    "print('F1:', f1)\n",
    "print('Precision', precision)\n",
    "print('Recall', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_oof = pd.DataFrame(train_oof_prob)\n",
    "test_pred = pd.DataFrame(test_pred_prob_list)\n",
    "\n",
    "train_oof.to_csv(os.path.join(PATH_TO_DATA, 'predictions/logreg_and_binary_preds_train.csv'), index=False)\n",
    "test_pred.to_csv(os.path.join(PATH_TO_DATA, 'predictions/logreg_and_binary_preds_test.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nteract": {
   "version": "0.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
